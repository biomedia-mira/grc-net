{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4w-Sd6Vu3MP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import monai\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.data import list_data_collate\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    Lambdad,\n",
    "    RandGaussianNoised,\n",
    "    RandBiasFieldd,\n",
    "    RandAdjustContrastd,\n",
    "    RandGaussianSmoothd,\n",
    "    RandGaussianSharpend,\n",
    "    RandGibbsNoised,\n",
    "    RandAffined,\n",
    "    EnsureTyped,\n",
    "    EnsureChannelFirstd,\n",
    ")\n",
    "import sys\n",
    "sys.path.append(\"anatomix\")\n",
    "from anatomix.segmentation.segmentation_utils import (\n",
    "    worker_init_fn,\n",
    "    load_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3LRZXMzHvfvW"
   },
   "outputs": [],
   "source": [
    "# Set Python, NumPy, and PyTorch seeds\n",
    "SEED = 12345\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# Ensure deterministic behavior in PyTorch\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTOYdikWvxoY"
   },
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_E9Nr5KkGF8X"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "n_trimages = 14\n",
    "n_valimages = 6\n",
    "\n",
    "df_tr_imgs = pd.read_csv('data/config/train.csv')\n",
    "df_tr_segs = pd.read_csv('data/config/train.seg.csv')\n",
    "df_val_imgs = pd.read_csv('data/config/val.csv')\n",
    "df_val_segs = pd.read_csv('data/config/val.seg.csv')\n",
    "\n",
    "trimages = sorted(df_tr_imgs['img'].tolist())[:n_trimages]\n",
    "trsegs   = sorted(df_tr_segs['img'].tolist())[:n_trimages]\n",
    "\n",
    "vaimages = sorted(df_val_imgs['img'].tolist())[:n_valimages]\n",
    "vasegs   = sorted(df_val_segs['img'].tolist())[:n_valimages]\n",
    "\n",
    "print('train images:', trimages)\n",
    "print('train segs  :', trsegs)\n",
    "print('val images  :', vaimages)\n",
    "print('val segs    :', vasegs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27NhpIgrxTtb"
   },
   "source": [
    "# Training and Few-shot Segmentation Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y1-CCAPDvMxt"
   },
   "outputs": [],
   "source": [
    "finetuning_amount = n_trimages  # amount of training set volumes to finetune on\n",
    "iters_per_epoch = 75  # how many iterations to do per \"epoch\"\n",
    "batch_size = 4  # batch size at every iteration\n",
    "n_epochs = 500  # number of \"epochs\" to finetune for\n",
    "lr = 2e-4  # learning rate for Adam\n",
    "crop_size = 96  # train on (96, 96, 96) crops\n",
    "spacing = 2.0\n",
    "val_interval = 5  # validation loop frequency in epochs\n",
    "n_classes = 7  # MM-WHS has 7 classes (background is already accounted for)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ZPFp9LyzrST"
   },
   "source": [
    "## MONAI dataloader preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aAMQLJ5eKoPv"
   },
   "outputs": [],
   "source": [
    "# Randomly select subset of training data for few-shot learning\n",
    "trimages = np.random.RandomState(seed=SEED).permutation(trimages).tolist()\n",
    "trsegs = np.random.RandomState(seed=SEED).permutation(trsegs).tolist()\n",
    "trimages = trimages[:finetuning_amount]\n",
    "trsegs = trsegs[:finetuning_amount]\n",
    "\n",
    "# Calculate repeats needed to achieve desired iterations per epoch\n",
    "samples_per_epoch = iters_per_epoch * batch_size\n",
    "repeats = max(1, samples_per_epoch // finetuning_amount)\n",
    "\n",
    "# Repeat training data to match desired samples per epoch\n",
    "trimages = trimages * repeats\n",
    "trsegs = trsegs * repeats\n",
    "\n",
    "train_files = [\n",
    "    {\"image\": img, \"label\": seg} for img, seg in zip(trimages, trsegs)\n",
    "]\n",
    "val_files = [\n",
    "    {\"image\": img, \"label\": seg} for img, seg in zip(vaimages, vasegs)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qz2Qh22TA88j"
   },
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import MapTransform\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from monai.data import MetaTensor\n",
    "\n",
    "def resample_image(\n",
    "    image: MetaTensor,\n",
    "    out_spacing=(1.0, 1.0, 1.0),\n",
    "    out_size=None,\n",
    "    is_label=False,\n",
    "    pad_value=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Resample a MetaTensor to given spacing and (optionally) size, matching the SITK logic.\n",
    "    \"\"\"\n",
    "\n",
    "    orig_affine = np.array(image.meta.get(\"affine\"))\n",
    "    orig_spacing = np.linalg.norm(orig_affine[:3, :3], axis=0)\n",
    "    direction = orig_affine[:3, :3] / orig_spacing\n",
    "    origin = orig_affine[:3, 3]\n",
    "\n",
    "    orig_size = np.array(image.shape[1:], dtype=int)\n",
    "\n",
    "    if out_size is None:\n",
    "        out_size = np.round(orig_size * orig_spacing / np.array(out_spacing)).astype(int)\n",
    "    else:\n",
    "        out_size = np.array(out_size, dtype=int)\n",
    "\n",
    "    orig_center = (orig_size - 1) / 2.0 * orig_spacing\n",
    "    out_center  = (out_size  - 1) / 2.0 * np.array(out_spacing)\n",
    "\n",
    "    orig_ctr_phys = direction.dot(orig_center)\n",
    "    out_ctr_phys  = direction.dot(out_center)\n",
    "    new_origin = origin + (orig_ctr_phys - out_ctr_phys)\n",
    "\n",
    "    new_affine = np.eye(4, dtype=float)\n",
    "    new_affine[:3, :3] = direction * np.array(out_spacing)\n",
    "    new_affine[:3, 3]  = new_origin\n",
    "\n",
    "    img = image.clone().detach()\n",
    "    dtype = img.dtype\n",
    "    if not is_label:\n",
    "        img = img.float()\n",
    "    img = img.unsqueeze(0)\n",
    "\n",
    "    mode = \"nearest\" if is_label else \"trilinear\"\n",
    "    align = False if mode == \"trilinear\" else None\n",
    "    resized = F.interpolate(img, size=tuple(out_size.tolist()), mode=mode, align_corners=align)\n",
    "\n",
    "    resized = resized.squeeze(0)\n",
    "    if is_label:\n",
    "        resized = resized.long()\n",
    "\n",
    "    new_meta = dict(image.meta)\n",
    "    new_meta[\"affine\"] = new_affine\n",
    "    new_meta[\"original_affine\"] = new_affine\n",
    "    new_meta[\"spatial_shape\"] = tuple(out_size.tolist())\n",
    "\n",
    "    return MetaTensor(resized, meta=new_meta)\n",
    "\n",
    "\n",
    "class Resamplerd(MapTransform):\n",
    "    \"\"\"\n",
    "    Resamples each array in `keys` to `out_spacing` and (optionally) `out_size`,\n",
    "    using nearest‐neighbour if `is_label=True`, else linear interpolation.\n",
    "    \"\"\"\n",
    "    def __init__(self, keys, out_spacing, out_size=None, is_label=False, allow_missing_keys=False):\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "        self.out_spacing = out_spacing\n",
    "        self.out_size     = out_size\n",
    "        self.is_label     = is_label\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.key_iterator(d):\n",
    "            # your existing resample_image takes (array, spacing, size, is_label)\n",
    "            d[key] = resample_image(\n",
    "                d[key],\n",
    "                self.out_spacing,\n",
    "                self.out_size,\n",
    "                self.is_label,\n",
    "            )\n",
    "        return d\n",
    "\n",
    "import SimpleITK as sitk\n",
    "def load_sitk_array(path):\n",
    "    img = sitk.ReadImage(path)\n",
    "    img = sitk.DICOMOrient(img, \"RAS\")\n",
    "    arr = sitk.GetArrayFromImage(img).astype(np.float32)\n",
    "    tensor = torch.from_numpy(arr)\n",
    "\n",
    "    meta = {\n",
    "        \"spacing\": img.GetSpacing(),\n",
    "        \"origin\": img.GetOrigin(),\n",
    "        \"direction\": (1, 0, 0, 0, 1, 0, 0, 0, 1),\n",
    "    }\n",
    "    return MetaTensor(tensor, meta=meta)\n",
    "\n",
    "def remap_labels(label):\n",
    "    remap_dict = {\n",
    "        0: 0, 205: 1, 420: 2, 500: 3, 550: 4, 600: 5, 820: 6, 850: 7,\n",
    "    }\n",
    "    for raw_val, class_idx in remap_dict.items():\n",
    "        label[label == raw_val] = class_idx\n",
    "    return label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentations\n",
    "the following augmentations worked best for the MM-WHS dataset, but feel free to change accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.config import KeysCollection\n",
    "from monai.transforms import MapTransform, Rand3DElasticd\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def invertHU(img: np.ndarray) -> np.ndarray:\n",
    "    arr = img.astype(np.float32, copy=True)\n",
    "    if np.random.rand() < 0.2:\n",
    "        # ensure we don’t modify original\n",
    "        mn, mx = float(arr.min()), float(arr.max())\n",
    "        # negative: white ↔ black\n",
    "        return (mx + mn) - arr\n",
    "    \n",
    "    return arr\n",
    "\n",
    "class RandPerSegmentElasticd(MapTransform):\n",
    "    def __init__(self, keys: KeysCollection, sigma_range, magnitude_range, prob=0.3):\n",
    "        super().__init__(keys)\n",
    "        self.prob = prob\n",
    "        self.elastic = Rand3DElasticd(\n",
    "            keys=keys,\n",
    "            sigma_range=sigma_range,\n",
    "            magnitude_range=magnitude_range,\n",
    "            prob=1.0,\n",
    "            spatial_size=None,\n",
    "            mode=(\"bilinear\", \"nearest\"),\n",
    "            padding_mode=\"zeros\",\n",
    "        )\n",
    "\n",
    "    def __call__(self, data):\n",
    "        if np.random.rand() > self.prob:\n",
    "            return data\n",
    "\n",
    "        d = dict(data)\n",
    "        image = d[self.keys[0]]\n",
    "        label = d[self.keys[1]]\n",
    "\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.numpy()\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            label = label.numpy()\n",
    "\n",
    "        image_out = np.copy(image)\n",
    "        label_out = np.zeros_like(label)\n",
    "\n",
    "        for cls in np.unique(label):\n",
    "            if cls == 0:\n",
    "                continue\n",
    "            mask = (label == cls).astype(np.float32)\n",
    "            img_masked = image * mask\n",
    "\n",
    "            sample = {\n",
    "                self.keys[0]: img_masked,\n",
    "                self.keys[1]: mask\n",
    "            }\n",
    "            aug = self.elastic(sample)\n",
    "\n",
    "            image_out = np.where(mask, aug[self.keys[0]], image_out)\n",
    "            label_out = np.where(mask, (aug[self.keys[1]] > 0.5) * cls, label_out)\n",
    "\n",
    "        d[self.keys[0]] = image_out.astype(np.float32)\n",
    "        d[self.keys[1]] = label_out.astype(np.float32)\n",
    "        return d\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from monai.transforms import MapTransform\n",
    "from monai.config import KeysCollection\n",
    "\n",
    "class RandPerSegmentInvertHUd(MapTransform):\n",
    "    def __init__(self, keys: KeysCollection, prob=0.2):\n",
    "        super().__init__(keys)\n",
    "        self.prob = prob\n",
    "\n",
    "    def __call__(self, data):\n",
    "        if np.random.rand() > self.prob:\n",
    "            return data\n",
    "\n",
    "        d = dict(data)\n",
    "        image = d[self.keys[0]]\n",
    "        label = d[self.keys[1]]\n",
    "\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.numpy()\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            label = label.numpy()\n",
    "\n",
    "        image_out = np.copy(image)\n",
    "        label_vals = [v for v in np.unique(label) if v != 0]\n",
    "        if not label_vals:\n",
    "            return d\n",
    "\n",
    "        # Choose random 1 to N segments\n",
    "        selected = np.random.choice(label_vals, size=np.random.randint(1, len(label_vals) + 1), replace=False)\n",
    "\n",
    "        for cls in selected:\n",
    "            mask = (label == cls)\n",
    "            if not np.any(mask):\n",
    "                continue\n",
    "            region_vals = image[mask]\n",
    "            vmin, vmax = region_vals.min(), region_vals.max()\n",
    "            image_out[mask] = (vmax + vmin) - image[mask]\n",
    "\n",
    "        d[self.keys[0]] = image_out.astype(np.float32)\n",
    "        return d\n",
    "\n",
    "def get_train_transforms(crop_size):\n",
    "    \"\"\"\n",
    "    Returns a MONAI composed transform object containing the specified\n",
    "    data augmentations for the training dataset.\n",
    "    \"\"\"\n",
    "    train_transforms = Compose(\n",
    "        [\n",
    "            Lambdad(keys=[\"image\", \"label\"], func=load_sitk_array),\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim='no_channel'),\n",
    "            EnsureTyped(keys=[\"image\", \"label\"]),\n",
    "            Resamplerd(keys=[\"image\", \"label\"], out_spacing=(spacing, spacing, spacing), out_size=(crop_size, crop_size, crop_size), is_label=[False, True]),\n",
    "            EnsureTyped(keys=[\"image\", \"label\"], dtype=torch.float32),\n",
    "            Lambdad(keys=\"label\", func=remap_labels),\n",
    "            RandPerSegmentElasticd(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                sigma_range=(1, 9),\n",
    "                magnitude_range=(1, 2),\n",
    "                prob=0.9\n",
    "            ),\n",
    "            RandPerSegmentInvertHUd(keys=[\"image\", \"label\"], prob=0.2),\n",
    "            RandGaussianNoised(keys=[\"image\"], prob=0.33),\n",
    "            RandBiasFieldd(keys=[\"image\"], prob=0.33, coeff_range=(0.0, 0.05)),\n",
    "            RandGibbsNoised(keys=[\"image\"], prob=0.33, alpha=(0.0, 0.33)),\n",
    "            RandAdjustContrastd(keys=[\"image\"], prob=0.33),\n",
    "            RandGaussianSmoothd(\n",
    "                keys=[\"image\"],\n",
    "                prob=0.33,\n",
    "                sigma_x=(0.0, 0.1), sigma_y=(0.0, 0.1), sigma_z=(0.0, 0.1),\n",
    "            ),\n",
    "            RandGaussianSharpend(keys=[\"image\"], prob=0.33),\n",
    "            RandAffined(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                prob=0.98,\n",
    "                mode=(\"bilinear\", \"nearest\"),\n",
    "                rotate_range=(np.pi/4, np.pi/4, np.pi/4),\n",
    "                scale_range=(0.4, 0.4, 0.4),\n",
    "                shear_range=(0.4, 0.4, 0.4),\n",
    "                spatial_size=(crop_size, crop_size, crop_size),\n",
    "                padding_mode='zeros',\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    return train_transforms\n",
    "\n",
    "def get_val_transforms():\n",
    "    val_transforms = Compose(\n",
    "        [\n",
    "            Lambdad(keys=[\"image\", \"label\"], func=load_sitk_array),\n",
    "            EnsureChannelFirstd(keys=[\"image\", \"label\"], channel_dim='no_channel'),\n",
    "            EnsureTyped(keys=[\"image\", \"label\"], device='cpu'),\n",
    "            EnsureTyped(keys=[\"image\", \"label\"], dtype=torch.float32),\n",
    "            Resamplerd(keys=[\"image\", \"label\"], out_spacing=(spacing, spacing, spacing), out_size=(crop_size, crop_size, crop_size), is_label=[False, True]),\n",
    "            EnsureTyped(keys=[\"image\", \"label\"], dtype=torch.float32),\n",
    "            Lambdad(keys=\"label\", func=remap_labels),\n",
    "        ]\n",
    "    )\n",
    "    return val_transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWj3KILiBDk1"
   },
   "source": [
    "## Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1xTy4xyIMQHZ"
   },
   "outputs": [],
   "source": [
    "# define transforms for image and segmentation\n",
    "train_transforms = get_train_transforms(crop_size=crop_size)\n",
    "val_transforms = get_val_transforms()\n",
    "\n",
    "# create a training data loader\n",
    "train_ds = monai.data.CacheDataset(\n",
    "    data=train_files, \n",
    "    transform=train_transforms,\n",
    "    cache_rate=1.0,\n",
    "    num_workers=6\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    collate_fn=list_data_collate,\n",
    "    worker_init_fn=worker_init_fn,\n",
    ")\n",
    "\n",
    "# create a validation data loader\n",
    "val_ds = monai.data.Dataset(data=val_files, transform=val_transforms)\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    collate_fn=list_data_collate,\n",
    "    worker_init_fn=worker_init_fn,\n",
    "    shuffle=True,\n",
    ") # TODO do pca 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Qv00DNT4C0b8",
    "outputId": "937b1f91-7a0b-49af-906b-28d73a6c68d2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "\n",
    "# Define a generic color map generator\n",
    "def get_colormap(num_classes):\n",
    "    cmap_base = plt.get_cmap('tab20', num_classes)\n",
    "    colors = cmap_base(np.linspace(0, 1, num_classes))\n",
    "    colors[0] = [0, 0, 0, 1]\n",
    "    return ListedColormap(colors)\n",
    "\n",
    "# Visualize batches\n",
    "for _ in range(5):\n",
    "    batch_data = next(iter(train_loader))\n",
    "    sampleimg, samplelab = batch_data[\"image\"], batch_data[\"label\"]\n",
    "\n",
    "    img = sampleimg.cpu().numpy()[0].squeeze()\n",
    "    lab = samplelab.cpu().numpy()[0].squeeze()\n",
    "\n",
    "    # Automatically determine number of classes from label\n",
    "    num_classes = int(lab.max()) + 1\n",
    "\n",
    "    plt.figure(figsize=(7, 3.5))\n",
    "    plt.suptitle(f'Batch {_}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img[48, :, :], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img[48, :, :], cmap='gray')\n",
    "    plt.imshow(lab[48, :, :], cmap=get_colormap(num_classes), alpha=0.6)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "for _ in range(1):\n",
    "    batch_data = next(iter(val_loader))\n",
    "    sampleimg, samplelab = batch_data[\"image\"], batch_data[\"label\"]\n",
    "\n",
    "    img = sampleimg.cpu().numpy()[0].squeeze()\n",
    "    lab = samplelab.cpu().numpy()[0].squeeze()\n",
    "\n",
    "    \n",
    "    \n",
    "    int(lab.max()) + 1\n",
    "\n",
    "    plt.figure(figsize=(7, 3.5))\n",
    "    plt.suptitle(f'Batch {_}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img[48, :, :], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(img[48, :, :], cmap='gray')\n",
    "    plt.imshow(lab[48, :, :], cmap=get_colormap(num_classes), alpha=0.6)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsLz_dzUCPoq"
   },
   "source": [
    "## Load pretrained model and initialize losses and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vg3B2U8UNBSD",
    "outputId": "edb48b55-5b6d-45b1-a481-26f27b2299f9"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "!nvidia-smi\n",
    "print(f\"using {device}\")\n",
    "new_model = load_model(\n",
    "    pretrained_ckpt='anatomix/model-weights/anatomix.pth',\n",
    "    n_classes=7, # 8 - 1 for MM-WHS\n",
    "    device=device,\n",
    ")\n",
    "!free -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ET-Dk4vxPDLJ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import monai\n",
    "from monai.losses import DiceCELoss, DiceLoss, GeneralizedDiceLoss\n",
    "\n",
    "# Volume-adaptive Dice (“Gen Dice”) excluding background\n",
    "gdice = GeneralizedDiceLoss(\n",
    "    include_background=False,\n",
    "    to_onehot_y=True,\n",
    "    softmax=True,\n",
    "    w_type=\"square\",\n",
    ")\n",
    "\n",
    "# Standard Dice + CE (equal-weight)\n",
    "dicece = DiceCELoss(\n",
    "    softmax=True,\n",
    "    to_onehot_y=True,\n",
    "    include_background=False,\n",
    ")\n",
    "\n",
    "loss_function = dicece\n",
    "\n",
    "valloss_function       = DiceLoss(\n",
    "    softmax=True,\n",
    "    to_onehot_y=True,\n",
    "    include_background=False,\n",
    ")\n",
    "other_valloss_name     = \"Gen Dice\"\n",
    "other_valloss_function = gdice\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    new_model.parameters(),\n",
    "    lr=lr,\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_MXgCIkCX4L"
   },
   "source": [
    "# Finetuning training loop\n",
    "\n",
    "Will take 10ish minutes to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ZCR1u54PqwG",
    "outputId": "60c2d556-6306-432f-f158-f3556b2f1422"
   },
   "outputs": [],
   "source": [
    "# start a typical PyTorch training\n",
    "best_val_loss = 10000000000\n",
    "anatomix_train_loss_values = []\n",
    "anatomix_val_loss_values = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(n_epochs), desc=\"training\"):\n",
    "    print(\"-\" * 10)\n",
    "    print(\"epoch {:04d}/{:04d}\".format(epoch + 1, n_epochs))\n",
    "    new_model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs = batch_data[\"image\"].to(device)\n",
    "        labels = batch_data[\"label\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = new_model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss /= step\n",
    "    anatomix_train_loss_values.append(epoch_loss)\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "    # Validation and checkpointing loop:\n",
    "    if ((epoch + 1) % val_interval == 0):\n",
    "        new_model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss = 0.0\n",
    "            val_loss_other_dice = 0.0\n",
    "            valstep = 0\n",
    "            for val_data in val_loader:\n",
    "                val_images = val_data[\"image\"].to(device)\n",
    "                val_labels = val_data[\"label\"].to(device)\n",
    "\n",
    "                # Validation set volumes can be of any spatial size\n",
    "                # So we're going to do sliding window inference at the\n",
    "                # same crop size that we trained at\n",
    "                roi_size = (crop_size, crop_size, crop_size)\n",
    "                sw_batch_size = 2\n",
    "                val_outputs = sliding_window_inference(\n",
    "                    val_images, roi_size, sw_batch_size,\n",
    "                    new_model, overlap=0.7,\n",
    "                )\n",
    "                \n",
    "                val_loss += valloss_function(val_outputs, val_labels)\n",
    "                val_loss_other_dice += other_valloss_function(val_outputs, val_labels)\n",
    "                valstep += 1\n",
    "\n",
    "            val_loss = val_loss / valstep\n",
    "            anatomix_val_loss_values.append(val_loss.item())\n",
    "\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_loss_epoch = epoch + 1\n",
    "                torch.save(new_model.state_dict(), f\"saved_models/segmentation/finetuned_MM-WHS{val_loss.item():.4f}.pth\")\n",
    "\n",
    "            print(\n",
    "                \"current epoch: {} current mean dice loss: {:.4f} ({} {:.4f})\"\n",
    "                \" best mean dice loss: {:.4f} at epoch {}\".format(\n",
    "                    epoch + 1, val_loss.item(), other_valloss_name, val_loss_other_dice.item(),\n",
    "                    best_val_loss.item(), best_loss_epoch,\n",
    "                )\n",
    "            )\n",
    "torch.save(new_model.state_dict(), \"saved_models/segmentation/anatomix_trained_MM-WHS.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "GRCNET",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
